# Inference_withTorchTensorRT
Comparing Deep Learning Inference of Pytorch models running on CPU, CUDA and TensorRT
<br>
<br>
![Thumbnail_Torch-TensorRT9](https://user-images.githubusercontent.com/32107652/154847750-b6641e53-f2e9-4646-aa6d-b5c91c86ff08.png)
<h2>YouTube Tutorial</h2>
https://youtu.be/iFADsRDJhDM
<br>
<h2>Please note</h2>
this .ipynb notebook is meant to run in a Torch TensorRT Docker container
<br>
or an Nvidia NGC container.
<br>
You can find detailed setup instructions is the video above.
<br>
<b>author:</b> Mariya Sha
<br>
<b>dependencies: </b> Pytorch, Torchvision, Panadas, TorchTensorRT
